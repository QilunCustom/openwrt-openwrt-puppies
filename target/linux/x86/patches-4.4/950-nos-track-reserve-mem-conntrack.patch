diff --git a/arch/x86/mm/pat.c b/arch/x86/mm/pat.c
index 188e3e0..a831e03 100644
--- a/arch/x86/mm/pat.c
+++ b/arch/x86/mm/pat.c
@@ -702,6 +702,8 @@ static inline int range_is_allowed(unsigned long pfn, unsigned long size)
 /* This check is needed to avoid cache aliasing when PAT is enabled */
 static inline int range_is_allowed(unsigned long pfn, unsigned long size)
 {
+/* Do not check devmem as nos track use this. */
+#if 0
 	u64 from = ((u64)pfn) << PAGE_SHIFT;
 	u64 to = from + size;
 	u64 cursor = from;
@@ -718,6 +720,7 @@ static inline int range_is_allowed(unsigned long pfn, unsigned long size)
 		cursor += PAGE_SIZE;
 		pfn++;
 	}
+#endif
 	return 1;
 }
 #endif /* CONFIG_STRICT_DEVMEM */
diff --git a/include/linux/nos_mempool.h b/include/linux/nos_mempool.h
new file mode 100644
index 0000000..a787e0e
--- /dev/null
+++ b/include/linux/nos_mempool.h
@@ -0,0 +1,62 @@
+#ifndef _NOS_MEMPOOL_H
+#define _NOS_MEMPOOL_H
+
+#include <linux/spinlock.h>
+#include <linux/kernel.h>
+#include <linux/ratelimit.h>
+
+struct nos_mempool {
+	spinlock_t lock;
+	void *head;
+	void **tail;
+	int nr_used;
+	int nr_free;
+	const char *name;
+};
+
+static __inline void
+nos_mempool_init(struct nos_mempool *pool, const char *name, int nr_used)
+{
+	spin_lock_init(&pool->lock);
+	pool->head = NULL;
+	pool->tail = &pool->head;
+	pool->nr_used = nr_used;
+	pool->nr_free = 0;
+	pool->name = name;
+}
+
+static __inline void *
+nos_mempool_get(struct nos_mempool *pool)
+{
+	void *data;
+
+	spin_lock_bh(&pool->lock);
+	data = pool->head;
+	if (data != NULL) {
+		pool->head = *(void **)data;
+		if (pool->head == NULL) {
+			pool->tail = &pool->head;
+		}
+		pool->nr_used++;
+		pool->nr_free--;
+	} else {
+		pr_warn_ratelimited("nos_mempool oom: %s, nr_used: %d, nr_free: %d\n",
+							pool->name, pool->nr_used, pool->nr_free);
+	}
+	spin_unlock_bh(&pool->lock);
+	return data;
+}
+
+static __inline void
+nos_mempool_put(struct nos_mempool *pool, void *data)
+{
+	spin_lock_bh(&pool->lock);
+	*(void **)data = NULL;
+	*pool->tail = data;
+	pool->tail = (void **)data;
+	pool->nr_used--;
+	pool->nr_free++;
+	spin_unlock_bh(&pool->lock);
+}
+
+#endif /* _NOS_MEMPOOL_H */
diff --git a/include/linux/nos_track.h b/include/linux/nos_track.h
new file mode 100644
index 0000000..27fadc3
--- /dev/null
+++ b/include/linux/nos_track.h
@@ -0,0 +1,100 @@
+#ifndef _NOS_TRACK_H
+#define _NOS_TRACK_H
+
+#ifdef __KERNEL__
+#include <linux/types.h>
+#endif
+
+/* use alloc_bootmem, do not need this :-~) */
+// #define START_RESERVE_MEM 	(16<<20) //arm/mips
+// #define START_RESERVE_MEM 	(0x10000000) //for x86, the low addr reserved by IO.
+
+#define SIZE_RESERVE_MEM 	(16<<22)
+#define SIZE_RESERVE_CAP 	(4<<22)
+
+#define NOS_USER_INFO_SIZE			(128)
+#define NOS_FLOW_INFO_SIZE			(64)
+
+/*
+* how to use the reserved kernel mem ? =>
+* 1/4: cap buffer,
+* 1/4: node users,
+* 1/4: node flow,
+* 1/4: statistic.
+*/
+#define NOS_USER_TRACK_MAX (SIZE_RESERVE_MEM / 4 / NOS_USER_INFO_SIZE)
+#define NOS_FLOW_TRACK_MAX (SIZE_RESERVE_MEM / 4 / NOS_FLOW_INFO_SIZE)
+
+#define NOS_USER_FLAGS_TYPE_USER 	(1<<0)
+
+#define NOS_USER_TRACK_TIMEOUT		(HZ * 3600 * 24) //hour ?
+
+typedef unsigned long utimes_t;
+typedef struct nos_user_hdr {
+	uint32_t flags; /*bitmap, status.*/
+	utimes_t time_stamp; /* notify, statistics */
+	uint32_t rule_magic; /* user node match ipset rule magic, as conf update, this need sync. */
+	uint32_t recv_bytes, xmit_bytes; /* statisc */
+	uint32_t recv_pkts, xmit_pkts;
+	int8_t rule_idx; /* user configure rule index. */
+	int8_t group_id;
+	int8_t dummy_pad[2];
+} user_hdr_t;
+
+typedef struct nos_flow_hdr {
+	uint32_t l7flags;
+	uint16_t status;
+	uint16_t l7proto;
+	utimes_t time_stamp;
+	uint32_t recv_bytes, xmit_bytes;
+	uint32_t recv_pkts, xmit_pkts; /* statistics */
+} flow_hdr_t;
+
+typedef struct nos_flow_tuple {
+	uint32_t ip_src;
+	uint32_t ip_dst;
+	uint16_t port_src;
+	uint16_t port_dst;
+	uint8_t  proto;
+	uint8_t  dir; 	//wan->lan, lan->wan, lan->lan, wan->wan.
+	uint8_t  inface;  //lan | wan.
+	uint8_t  dummy_pad;
+} flow_tuple_t;
+
+
+/* each node have 16 byte header */
+#define NOS_USER_DATA_SIZE (NOS_USER_INFO_SIZE - 16 - sizeof(struct nos_user_hdr))
+#define NOS_FLOW_DATA_SIZE (NOS_FLOW_INFO_SIZE - 16 - sizeof(struct nos_flow_tuple) - sizeof(struct nos_flow_hdr))
+typedef struct nos_user_info {
+	/* !!! keep this 16 byte header sync, DO not modify !!! */
+	uint32_t magic;
+	uint32_t id;
+	uint32_t refcnt;
+	uint32_t ip;
+	/* end */
+
+	struct nos_user_hdr hdr;
+
+	char private[NOS_USER_DATA_SIZE];
+} user_info_t;
+
+typedef struct nos_flow_info {
+	/* !!! keep this 16 byte header sync, DO not modify !!! */
+	uint32_t magic;
+	uint32_t id;
+	uint32_t user_id;
+	uint32_t peer_id;
+	/* end */
+
+	struct nos_flow_tuple tuple;
+	struct nos_flow_hdr hdr;
+
+	char private[NOS_FLOW_DATA_SIZE];
+} flow_info_t;
+
+
+#ifdef __KERNEL__
+#include <linux/nos_track_priv.h>
+#endif
+
+#endif /* _NOS_TRACK_H */
diff --git a/include/linux/nos_track_priv.h b/include/linux/nos_track_priv.h
new file mode 100644
index 0000000..29135e4
--- /dev/null
+++ b/include/linux/nos_track_priv.h
@@ -0,0 +1,92 @@
+#ifndef _NOS_TRACK_PRIV_H__
+#define _NOS_TRACK_PRIV_H__
+
+#include <asm/atomic.h>
+#include <linux/list.h>
+#include <linux/types.h>
+#include <linux/rculist.h>
+#include <linux/spinlock.h>
+#include <linux/rbtree.h>
+#include <linux/timer.h>
+#include <linux/skbuff.h>
+
+struct tbq_backlog {
+	struct list_head list;
+	struct tbq_token_ctrl *tc;
+	uint32_t octets;
+	uint32_t weight;
+	int32_t drr_deficit;
+};
+
+struct tbq_flow_backlog {
+	struct tbq_backlog base;
+	struct list_head packets;
+	struct tbq_flow_track *tf;
+};
+
+struct tbq_flow_track {
+	struct list_head list;
+	uint16_t dummy;
+	uint16_t app_id;
+	uint16_t uname_match;	//mo
+	uint32_t rule_mask;
+	uint8_t weight[32];
+	struct tbq_flow_backlog backlog[2];
+};
+
+struct nos_track {
+	struct nos_flow_info *flow;
+	struct nos_user_info *user;
+	struct nos_user_info *peer;
+	struct tbq_flow_track tbq;
+};
+
+struct nos_user_track {
+	uint32_t ip;
+	uint32_t magic;
+	struct hlist_node hash_node;
+	struct timer_list timeout;
+	spinlock_t lock;
+	uint32_t refcnt;
+	uint32_t flags;
+	void *tbq;
+};
+
+struct nos_flow_track {
+	uint32_t magic;
+	struct nos_user_track *user;
+	struct nos_user_track *peer;
+};
+
+struct nos_track_event {
+	struct list_head list;
+	void (* on_user_free)(struct nos_user_track *);
+	void (* on_flow_free)(struct tbq_flow_track *);
+};
+
+struct nos_track_stats {
+	atomic64_t nr_flow_alloc;
+	atomic64_t nr_flow_free;
+	atomic64_t nr_ring_drop;
+};
+
+typedef int (*nos_user_match_fn_t)(struct nos_user_info *ui, struct sk_buff *skb);
+extern nos_user_match_fn_t nos_user_match_fn;
+
+extern struct resource nosmem_res;
+extern struct nos_track_stats *nos_track_stats;
+extern void* nos_track_cap_base;
+extern uint32_t nos_track_cap_size;
+
+
+int nos_track_init(void);
+int nos_track_alloc(struct nos_track *track, struct nos_flow_tuple *tuple, struct sk_buff *skb);
+void nos_track_free(struct nos_track *track);
+
+struct nos_user_track *nos_get_user_track(struct nos_track *track);
+struct nos_flow_track *nos_get_flow_track(struct nos_track *track);
+
+void nos_track_event_register(struct nos_track_event *ev);
+void nos_track_event_unregister(struct nos_track_event *ev);
+
+#endif /* _NOS_TRACK_PRIV_H__ */
diff --git a/include/net/netfilter/nf_conntrack.h b/include/net/netfilter/nf_conntrack.h
index fde4068..880491c 100644
--- a/include/net/netfilter/nf_conntrack.h
+++ b/include/net/netfilter/nf_conntrack.h
@@ -18,6 +18,8 @@
 #include <linux/compiler.h>
 #include <linux/atomic.h>
 
+#include <linux/nos_track.h>
+
 #include <linux/netfilter/nf_conntrack_tcp.h>
 #include <linux/netfilter/nf_conntrack_dccp.h>
 #include <linux/netfilter/nf_conntrack_sctp.h>
@@ -114,6 +116,9 @@ struct nf_conn {
 	/* Extensions */
 	struct nf_ct_ext *ext;
 
+	/* nos track kernel private */
+	struct nos_track nos_track;
+
 	/* Storage reserved for other modules, must be the last member */
 	union nf_conntrack_proto proto;
 };
@@ -164,6 +169,18 @@ nf_ct_get(const struct sk_buff *skb, enum ip_conntrack_info *ctinfo)
 	return (struct nf_conn *)skb->nfct;
 }
 
+static inline struct nos_track*
+nf_ct_get_nos(struct nf_conn *ct)
+{
+	struct nos_track* nos = &ct->nos_track;
+
+	/* FIXME: some more check need. */
+	if(nos->flow && nos->user && nos->peer) {
+		return nos;
+	}
+	return NULL;
+}
+
 /* decrement reference count on a conntrack */
 static inline void nf_ct_put(struct nf_conn *ct)
 {
diff --git a/include/uapi/linux/Kbuild b/include/uapi/linux/Kbuild
index 16028e1..59dc04a 100644
--- a/include/uapi/linux/Kbuild
+++ b/include/uapi/linux/Kbuild
@@ -462,3 +462,4 @@ header-y += xilinx-v4l2-controls.h
 header-y += zorro.h
 header-y += zorro_ids.h
 header-y += userfaultfd.h
+header-y += nos_track.h
diff --git a/include/uapi/linux/nos_track.h b/include/uapi/linux/nos_track.h
new file mode 120000
index 0000000..a9015a4
--- /dev/null
+++ b/include/uapi/linux/nos_track.h
@@ -0,0 +1 @@
+../../linux/nos_track.h
\ No newline at end of file
diff --git a/init/main.c b/init/main.c
index eae7418..e73082f 100644
--- a/init/main.c
+++ b/init/main.c
@@ -517,6 +517,7 @@ static void __init mm_init(void)
 	ioremap_huge_init();
 }
 
+extern void __init ntrack_mem_reserve(void);
 asmlinkage __visible void __init start_kernel(void)
 {
 	char *command_line;
@@ -549,6 +550,7 @@ asmlinkage __visible void __init start_kernel(void)
 	page_address_init();
 	pr_notice("%s", linux_banner);
 	setup_arch(&command_line);
+	ntrack_mem_reserve();
 	mm_init_cpumask(&init_mm);
 	mangle_bootargs(command_line);
 	setup_command_line(command_line);
diff --git a/kernel/Makefile b/kernel/Makefile
index e1b7438..71a6574 100644
--- a/kernel/Makefile
+++ b/kernel/Makefile
@@ -9,7 +9,7 @@ obj-y     = fork.o exec_domain.o panic.o \
 	    extable.o params.o \
 	    kthread.o sys_ni.o nsproxy.o \
 	    notifier.o ksysfs.o cred.o reboot.o \
-	    async.o range.o smpboot.o
+	    async.o range.o smpboot.o nos_track.o
 
 obj-$(CONFIG_MULTIUSER) += groups.o
 
diff --git a/kernel/nos_track.c b/kernel/nos_track.c
new file mode 100644
index 0000000..f69c78b
--- /dev/null
+++ b/kernel/nos_track.c
@@ -0,0 +1,473 @@
+#include <linux/nos_track.h>
+#include <linux/nos_mempool.h>
+#include <linux/bootmem.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/ioport.h>
+#include <linux/slab.h>
+#include <linux/timer.h>
+
+
+#define NOS_USER_TRACK_HASH_SIZE 	(NOS_USER_TRACK_MAX / 4)
+
+struct nos_track_stats *nos_track_stats;
+EXPORT_SYMBOL(nos_track_stats);
+
+static struct nos_user_track nos_user_tracks[NOS_USER_TRACK_MAX];
+static struct nos_flow_track nos_flow_tracks[NOS_FLOW_TRACK_MAX];
+
+static struct nos_mempool nos_user_track_pool;
+static struct nos_mempool nos_flow_track_pool;
+
+static struct hlist_head nos_user_track_hash[NOS_USER_TRACK_HASH_SIZE];
+static spinlock_t nos_user_track_hash_lock;
+
+static atomic_t nos_user_magic = ATOMIC_INIT(0);
+static atomic_t nos_flow_magic = ATOMIC_INIT(0);
+
+static struct nos_user_info *nos_user_info_base;
+static struct nos_flow_info *nos_flow_info_base;
+
+static struct {
+	struct list_head list;
+	spinlock_t lock;
+} nos_track_events;
+
+static void nos_user_track_put(struct nos_user_track *);
+
+static void utrack_timeout_fn(unsigned long d)
+{
+	struct nos_user_track *ut = (struct nos_user_track*)d;
+
+	nos_user_track_put(ut);
+}
+
+static struct nos_user_info *
+nos_user_info_init(struct nos_user_track *ut)
+{
+	int32_t user_id = ut - nos_user_tracks;
+	struct nos_user_info *ui = nos_user_info_base + user_id;
+
+	ui->id = user_id;
+	ui->ip = ut->ip;
+	ui->refcnt = ut->refcnt;
+
+	memset(&ui->hdr, 0, sizeof(ui->hdr));
+	memset(ui->private, 0, sizeof(ui->private));
+
+	smp_wmb();
+
+	ui->magic = ut->magic;
+
+	return ui;
+}
+
+static inline void
+nos_user_info_update_refcnt(struct nos_user_track *ut)
+{
+	int32_t user_id = ut - nos_user_tracks;
+	struct nos_user_info *ui = nos_user_info_base + user_id;
+	ui->refcnt = ut->refcnt;
+}
+
+static struct nos_flow_info *
+nos_flow_info_init(struct nos_flow_track *ft, struct nos_flow_tuple *tuple)
+{
+	int32_t flow_id = ft - nos_flow_tracks;
+	struct nos_flow_info *fi = nos_flow_info_base + flow_id;
+
+	fi->id = flow_id;
+	fi->user_id = ft->user - nos_user_tracks;
+	fi->peer_id = ft->peer - nos_user_tracks;
+	fi->tuple = *tuple;
+
+	memset(fi->private, 0, sizeof(fi->private));
+
+	smp_wmb();
+
+	fi->magic = ft->magic;
+
+	return fi;
+}
+
+static inline int utrack_is_user(struct nos_user_track *ut)
+{
+	return ut->flags & NOS_USER_FLAGS_TYPE_USER;
+}
+nos_user_match_fn_t nos_user_match_fn = NULL;
+
+static struct nos_user_track *nos_user_track_get(uint32_t ip, struct sk_buff *skb)
+{
+	struct nos_user_track *user;
+	struct nos_user_info *ui;
+	struct hlist_head *slot;
+	uint32_t slot_index;
+	nos_user_match_fn_t fn;
+
+	slot_index = ip % NOS_USER_TRACK_HASH_SIZE;
+
+	spin_lock_bh(&nos_user_track_hash_lock);
+
+	slot = &nos_user_track_hash[slot_index];
+
+	hlist_for_each_entry(user, slot, hash_node) {
+		if (user->ip == ip) {
+			spin_lock_bh(&user->lock);
+			if (user->refcnt == 0) {
+				spin_unlock_bh(&user->lock);
+				break;
+			}
+			++user->refcnt;
+			nos_user_info_update_refcnt(user);
+			spin_unlock_bh(&user->lock);
+			goto out;
+		}
+	}
+
+	user = nos_mempool_get(&nos_user_track_pool);
+	if (user == NULL) {
+		goto out;
+	}
+
+	user->ip = ip;
+	user->refcnt = 1;
+	user->magic = atomic_add_return(2, &nos_user_magic);
+	spin_lock_init(&user->lock);
+
+	/* is user or peer ? */
+	ui = nos_user_info_init(user);
+	fn = rcu_dereference(nos_user_match_fn);
+	if (fn && skb && fn(ui, skb)) {
+		/* mark user */
+		user->flags |= NOS_USER_FLAGS_TYPE_USER;
+		++ user->refcnt;
+		setup_timer(&user->timeout, utrack_timeout_fn, (unsigned long)user);
+		user->timeout.expires = jiffies + NOS_USER_TRACK_TIMEOUT;
+		add_timer(&user->timeout);
+	}
+
+	hlist_add_head(&user->hash_node, slot);
+	user->tbq = NULL;
+
+#if 0
+	printk("[nos_track] ADD USER: %pI4h\t(%6d / %6d)\n",
+			&ip, nos_user_track_pool.nr_used, nos_user_track_pool.nr_free);
+#endif
+
+out:
+	spin_unlock_bh(&nos_user_track_hash_lock);
+	return user;
+}
+EXPORT_SYMBOL(nos_user_match_fn);
+
+static void
+nos_user_track_put(struct nos_user_track *user)
+{
+	struct nos_track_event *ev;
+	int32_t refcnt;
+
+	BUG_ON(user == NULL);
+
+	spin_lock_bh(&user->lock);
+	refcnt = --user->refcnt;
+	nos_user_info_update_refcnt(user);
+	spin_unlock_bh(&user->lock);
+
+	BUG_ON(refcnt < 0);
+
+	if (refcnt != 0)
+		return;
+
+	spin_lock_bh(&nos_track_events.lock);
+	list_for_each_entry(ev, &nos_track_events.list, list) {
+		ev->on_user_free(user);
+	}
+	spin_unlock_bh(&nos_track_events.lock);
+
+	BUG_ON(user->tbq != NULL);
+
+	// set delete mark
+	nos_user_info_base[user - nos_user_tracks].magic = user->magic | 1U;
+
+	spin_lock_bh(&nos_user_track_hash_lock);
+	hlist_del(&user->hash_node);
+	spin_unlock_bh(&nos_user_track_hash_lock);
+#if 0
+	printk("[nos_track] DEL: %pI4h\t(%6d / %6d)\n",
+			&user->ip, nos_user_track_pool.nr_used - 1, nos_user_track_pool.nr_free + 1);
+#endif
+	nos_mempool_put(&nos_user_track_pool, user);
+}
+
+static void
+nos_track_check(struct nos_track *track)
+{
+	struct nos_flow_info *fi = track->flow;
+	struct nos_user_info *ui_src = track->user;
+	struct nos_user_info *ui_dst = track->peer;
+	uint32_t user_id = ui_src - nos_user_info_base;
+	uint32_t peer_id = ui_dst - nos_user_info_base;
+
+	if (user_id >= NOS_USER_TRACK_MAX || user_id != fi->user_id) {
+		pr_warn_ratelimited("nos_flow_info error: %d, %d\n", user_id, fi->user_id);
+	}
+
+	if (peer_id >= NOS_USER_TRACK_MAX || peer_id != fi->peer_id) {
+		pr_warn_ratelimited("nos_flow_info error: %d, %d\n", peer_id, fi->peer_id);
+	}
+}
+
+int
+nos_track_alloc(struct nos_track *track, struct nos_flow_tuple *tuple, struct sk_buff *skb)
+{
+	struct nos_flow_track *flow = NULL;
+	struct nos_user_track *user = NULL;
+	struct nos_user_track *peer = NULL;
+
+	flow = nos_mempool_get(&nos_flow_track_pool);
+	if (flow == NULL)
+		goto fail;
+
+	user = nos_user_track_get(tuple->ip_src, skb);
+	peer = nos_user_track_get(tuple->ip_dst, NULL);
+
+	if (user == NULL || peer == NULL)
+		goto fail;
+
+	if (utrack_is_user(user)) {
+		flow->user = user;
+		flow->peer = peer;
+	} else if (utrack_is_user(peer)) {
+		flow->user = peer;
+		flow->peer = user;
+	} else {
+		flow->user = user;
+		flow->peer = peer;
+	}
+
+	flow->magic = atomic_add_return(2, &nos_flow_magic);
+
+	track->flow = nos_flow_info_init(flow, tuple);
+	track->user = &nos_user_info_base[track->flow->user_id];
+	track->peer = &nos_user_info_base[track->flow->peer_id];
+	atomic64_inc(&nos_track_stats->nr_flow_alloc);
+
+	memset(&track->tbq, 0, sizeof(track->tbq));
+
+	return 0;
+
+fail:
+	if (flow != NULL) {
+		if (user != NULL)
+			nos_user_track_put(user);
+		if (peer != NULL)
+			nos_user_track_put(peer);
+		nos_mempool_put(&nos_flow_track_pool, flow);
+	}
+	track->flow = NULL;
+	track->user = NULL;
+	track->peer = NULL;
+	return -1;
+}
+EXPORT_SYMBOL(nos_track_alloc);
+
+void
+nos_track_free(struct nos_track *track)
+{
+	struct nos_flow_track *flow;
+	struct nos_track_event *ev;
+	int flow_id;
+
+	if (track->flow == NULL) {
+		return;
+	}
+
+	flow_id = track->flow - nos_flow_info_base;
+	BUG_ON(flow_id < 0 || flow_id >= NOS_FLOW_TRACK_MAX);
+
+	nos_track_check(track);
+
+	flow = &nos_flow_tracks[flow_id];
+
+	spin_lock_bh(&nos_track_events.lock);
+	list_for_each_entry(ev, &nos_track_events.list, list) {
+		ev->on_flow_free(&track->tbq);
+	}
+	spin_unlock_bh(&nos_track_events.lock);
+
+	track->flow->magic = flow->magic | 1U; // delete mark
+
+	nos_user_track_put(flow->user);
+	nos_user_track_put(flow->peer);
+
+	nos_mempool_put(&nos_flow_track_pool, flow);
+
+	atomic64_inc(&nos_track_stats->nr_flow_free);
+}
+EXPORT_SYMBOL(nos_track_free);
+
+struct nos_user_track *
+nos_get_user_track(struct nos_track *track)
+{
+	int user_id;
+
+	BUG_ON(track->flow == NULL);
+	BUG_ON(track->user == NULL);
+	BUG_ON(track->peer == NULL);
+
+	user_id = track->user - nos_user_info_base;
+	BUG_ON(user_id < 0 || user_id >= NOS_USER_TRACK_MAX);
+	return nos_user_tracks + user_id;
+}
+EXPORT_SYMBOL(nos_get_user_track);
+
+struct nos_flow_track *
+nos_get_flow_track(struct nos_track *track)
+{
+	int flow_id;
+
+	BUG_ON(track->flow == NULL);
+	BUG_ON(track->user == NULL);
+	BUG_ON(track->peer == NULL);
+
+	flow_id = track->flow - nos_flow_info_base;
+	BUG_ON(flow_id < 0 || flow_id >= NOS_FLOW_TRACK_MAX);
+	return nos_flow_tracks + flow_id;
+}
+EXPORT_SYMBOL(nos_get_flow_track);
+
+void nos_track_event_register(struct nos_track_event *ev)
+{
+	spin_lock_bh(&nos_track_events.lock);
+	list_add_tail(&ev->list, &nos_track_events.list);
+	spin_unlock_bh(&nos_track_events.lock);
+}
+EXPORT_SYMBOL(nos_track_event_register);
+
+void nos_track_event_unregister(struct nos_track_event *ev)
+{
+	spin_lock_bh(&nos_track_events.lock);
+	list_del(&ev->list);
+	spin_unlock_bh(&nos_track_events.lock);
+}
+EXPORT_SYMBOL(nos_track_event_unregister);
+
+struct resource nosmem_res = {
+	.name  = "nos track",
+	.start = 0,
+	.end   = SIZE_RESERVE_MEM - 1,
+	.flags = IORESOURCE_BUSY | IORESOURCE_MEM | IORESOURCE_DMA
+};
+
+/* for sysctl read */
+unsigned long nt_shm_base = 0;
+uint32_t 	nt_shm_size = 0;
+uint32_t 	nt_cap_block_sz = 0;
+uint32_t 	nt_user_offset = 0;
+uint32_t 	nt_flow_offset = 0;
+/* for modules use */
+void 		*nos_track_cap_base = NULL;
+uint32_t 	nos_track_cap_size = 0;
+EXPORT_SYMBOL(nt_cap_block_sz);
+EXPORT_SYMBOL(nos_track_cap_base);
+EXPORT_SYMBOL(nos_track_cap_size);
+
+int nos_track_init()
+{
+	int i;
+
+	if(!nosmem_res.start) {
+		printk("nos track reserve mem nil.\n");
+		return -ENOMEM;
+	}
+
+	nos_track_cap_base = phys_to_virt(nosmem_res.start);
+	nos_track_cap_size = SIZE_RESERVE_CAP;
+	printk("nos_track_cap_base: %p-%p, size: %x\n",
+		nos_track_cap_base, (void*)nosmem_res.start, nos_track_cap_size);
+
+	nos_user_info_base = phys_to_virt(nosmem_res.start + (SIZE_RESERVE_CAP));
+	nos_flow_info_base = (void *)(nos_user_info_base + NOS_USER_TRACK_MAX);
+	nos_track_stats = (void *)(nos_flow_info_base + NOS_FLOW_TRACK_MAX);
+
+	nt_shm_base = (unsigned long)(nosmem_res.start);
+	nt_shm_size = (unsigned long)(nosmem_res.end - nosmem_res.start + 1);
+	nt_user_offset = (unsigned long)nos_user_info_base - (unsigned long)nos_track_cap_base;
+	nt_flow_offset = (unsigned long)nos_flow_info_base - (unsigned long)nos_track_cap_base;
+
+	printk("nos shm: %p size: %p\n", (void*)nt_shm_base, (void*)nt_shm_size);
+
+	printk("nos_user_info_base: %p (phys: %x)\n",
+		nos_user_info_base, virt_to_phys(nos_user_info_base));
+	printk("nos_flow_info_base: %p (phys: %x)\n",
+		nos_flow_info_base, virt_to_phys(nos_flow_info_base));
+	printk("nos_track_stats: %p (phys: %x)\n",
+		nos_track_stats, virt_to_phys(nos_track_stats));
+
+	if (virt_to_phys(nos_track_stats + 1) > nosmem_res.end) {
+		printk("nosmem_res oom: [%llu - %llu]\n", (uint64_t)nosmem_res.start, (uint64_t)nosmem_res.end);
+		return -1;
+	}
+
+	// delete mark: magic & 1 == 1
+	memset(nos_user_info_base, 0xAF, NOS_USER_TRACK_MAX * sizeof(struct nos_user_info));
+	memset(nos_flow_info_base, 0xBF, NOS_FLOW_TRACK_MAX * sizeof(struct nos_flow_info));
+
+	nos_mempool_init(&nos_user_track_pool, "nos_user_track", NOS_USER_TRACK_MAX);
+	for (i = 0; i < NOS_USER_TRACK_MAX; i++) {
+		nos_mempool_put(&nos_user_track_pool, &nos_user_tracks[i]);
+	}
+
+	nos_mempool_init(&nos_flow_track_pool, "nos_flow_track", NOS_FLOW_TRACK_MAX);
+	for (i = 0; i < NOS_FLOW_TRACK_MAX; i++) {
+		nos_mempool_put(&nos_flow_track_pool, &nos_flow_tracks[i]);
+	}
+
+	spin_lock_init(&nos_user_track_hash_lock);
+	for (i = 0; i < NOS_USER_TRACK_HASH_SIZE; i++) {
+		INIT_HLIST_HEAD(&nos_user_track_hash[i]);
+	}
+
+	INIT_LIST_HEAD(&nos_track_events.list);
+	spin_lock_init(&nos_track_events.lock);
+
+	printk("nos_track_init() OK [user size: %d, flow size: %d]\n",
+		(int)sizeof(struct nos_user_info), (int)sizeof(struct nos_flow_info));
+	printk("\t[user priv size: %d, flow priv size: %d]\n",
+		NOS_USER_DATA_SIZE, NOS_FLOW_DATA_SIZE);
+
+	return 0;
+}
+EXPORT_SYMBOL(nos_track_init);
+
+/* kernel reserve memory */
+void __init ntrack_mem_reserve(void)
+{
+	int ret;
+	void *base;
+	unsigned long long size = 0;
+
+	if(!size)
+		size = nosmem_res.end - nosmem_res.start + 1;
+
+	base = alloc_bootmem(size);
+	if (!base) {
+		nosmem_res.start = 0;
+		pr_warn("nos reservation failed - mem in use %lx\n", (unsigned long)base);
+		return;
+	}
+
+	nosmem_res.start = virt_to_phys(base);
+	nosmem_res.end = nosmem_res.start + size - 1;
+	ret = insert_resource(&iomem_resource, &nosmem_res);
+	if (ret) {
+		// nosmem_res.start = 0;
+		pr_err("Resource %ldMB of mem at %ldMB for nos_track failed. %d\n",
+			((unsigned long)size >> 20),
+			((unsigned long)virt_to_phys(base) >> 20), ret);
+	} else {
+		pr_info("Resource %ldMB of mem at %ldMB for nos_track.\n",
+			((unsigned long)size >> 20),
+			((unsigned long)virt_to_phys(base) >> 20));
+	}
+}
diff --git a/kernel/sysctl.c b/kernel/sysctl.c
index dc6858d..d1aea27 100644
--- a/kernel/sysctl.c
+++ b/kernel/sysctl.c
@@ -276,6 +276,12 @@ static int min_extfrag_threshold;
 static int max_extfrag_threshold = 1000;
 #endif
 
+extern unsigned long nt_shm_base;
+extern uint32_t nt_shm_size;
+extern uint32_t nt_cap_block_sz;
+extern uint32_t nt_user_offset;
+extern uint32_t nt_flow_offset;
+
 static struct ctl_table kern_table[] = {
 	{
 		.procname	= "sched_child_runs_first",
@@ -284,6 +290,41 @@ static struct ctl_table kern_table[] = {
 		.mode		= 0644,
 		.proc_handler	= proc_dointvec,
 	},
+	{
+		.procname	= "nt_shm_base",
+		.data		= &nt_shm_base,
+		.maxlen		= sizeof(void*),
+		.mode		= 0444,
+		.proc_handler	= proc_doulongvec_minmax,
+	},
+	{
+		.procname	= "nt_shm_size",
+		.data		= &nt_shm_size,
+		.maxlen		= sizeof(unsigned int),
+		.mode		= 0444,
+		.proc_handler	= proc_dointvec,
+	},
+	{
+		.procname	= "nt_cap_block_sz",
+		.data		= &nt_cap_block_sz,
+		.maxlen		= sizeof(unsigned int),
+		.mode		= 0444,
+		.proc_handler	= proc_dointvec,
+	},
+	{
+		.procname	= "nt_user_offset",
+		.data		= &nt_user_offset,
+		.maxlen		= sizeof(unsigned int),
+		.mode		= 0444,
+		.proc_handler	= proc_dointvec,
+	},
+	{
+		.procname	= "nt_flow_offset",
+		.data		= &nt_flow_offset,
+		.maxlen		= sizeof(unsigned int),
+		.mode		= 0444,
+		.proc_handler	= proc_dointvec,
+	},
 #ifdef CONFIG_SCHED_DEBUG
 	{
 		.procname	= "sched_min_granularity_ns",
diff --git a/net/netfilter/nf_conntrack_core.c b/net/netfilter/nf_conntrack_core.c
index 3cb3cb8..f190cad 100644
--- a/net/netfilter/nf_conntrack_core.c
+++ b/net/netfilter/nf_conntrack_core.c
@@ -889,6 +889,9 @@ void nf_conntrack_free(struct nf_conn *ct)
 {
 	struct net *net = nf_ct_net(ct);
 
+	/* nos node release */
+	nos_track_free(&ct->nos_track);
+
 	/* A freed object has refcnt == 0, that's
 	 * the golden rule for SLAB_DESTROY_BY_RCU
 	 */
@@ -922,6 +925,7 @@ init_conntrack(struct net *net, struct nf_conn *tmpl,
 	struct nf_conn_timeout *timeout_ext;
 	struct nf_conntrack_zone tmp;
 	unsigned int *timeouts;
+	struct nos_flow_tuple nos_flow_tuple;
 
 	if (!nf_ct_invert_tuple(&repl_tuple, tuple, l3proto, l4proto)) {
 		pr_debug("Can't invert tuple.\n");
@@ -948,6 +952,14 @@ init_conntrack(struct net *net, struct nf_conn *tmpl,
 		timeouts = l4proto->get_timeouts(net);
 	}
 
+	/* roy: nos track init nodes */
+	nos_flow_tuple.ip_src = __be32_to_cpu(tuple->src.u3.ip);
+	nos_flow_tuple.ip_dst = __be32_to_cpu(tuple->dst.u3.ip);
+	nos_flow_tuple.port_src = __be16_to_cpu(tuple->src.u.all);
+	nos_flow_tuple.port_dst = __be16_to_cpu(tuple->dst.u.all);
+	nos_flow_tuple.proto = tuple->dst.protonum;
+	nos_track_alloc(&ct->nos_track, &nos_flow_tuple, skb);
+
 	if (!l4proto->new(ct, skb, dataoff, timeouts)) {
 		nf_conntrack_free(ct);
 		pr_debug("init conntrack: can't track with proto module\n");
@@ -1635,6 +1647,12 @@ int nf_conntrack_init_start(void)
 	int max_factor = 8;
 	int i, ret, cpu;
 
+	ret = nos_track_init();
+	if (ret < 0) {
+		printk("%s: nos track init failed. %d\n", __FUNCTION__, ret);
+		return ret;
+	}
+
 	for (i = 0; i < CONNTRACK_LOCKS; i++)
 		spin_lock_init(&nf_conntrack_locks[i]);
 
